{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "natural-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import resample\n",
    "from bayes_opt import BayesianOptimization\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suburban-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/X_train_TS25_RS3.csv')\n",
    "X_test = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/X_test_TS25_RS3.csv')\n",
    "y_train = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/y_train_TS25_RS3.csv')\n",
    "y_test = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/y_test_TS25_RS3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nasty-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_X_train = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/Narrow_X_train_TS25_RS3.csv')\n",
    "Narrow_X_test = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/Narrow_X_test_TS25_RS3.csv')\n",
    "Narrow_y_train = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/Narrow_y_train_TS25_RS3.csv')\n",
    "Narrow_y_test = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/Narrow_y_test_TS25_RS3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sized-lloyd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problemtype: medical : Catch all isntances of event, false positives are less of a problem. Maximize: Sensitivity, and Precision\n",
      "problemtype: spam: Catch many instances of event, but minimize FP\n",
      "problem type: Artisinal, run time less important than accuracy\n",
      "problem type: Enterprise, run time is a priority\n"
     ]
    }
   ],
   "source": [
    "print('problemtype: medical : Catch all isntances of event, false positives are less of a problem. Maximize: Sensitivity, and Precision')\n",
    "print('problemtype: spam: Catch many instances of event, but minimize FP')\n",
    "print('problem type: Artisinal, run time less important than accuracy')\n",
    "print('problem type: Enterprise, run time is a priority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "close-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_buddy(model_to_fit, dictionary_string, dicto):\n",
    "    funky_time_start = time.time()\n",
    "    model_to_fit.fit(X_train, np.ravel(y_train))\n",
    "    funky_time_stop = time.time()\n",
    "    funky_train_time = funky_time_stop - funky_time_start\n",
    "    dicto[dictionary_string]['training_time'] = funky_train_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "standing-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confused_buddy(model_to_confuse, dictionary_string,dicto):\n",
    "    confuse = confusion_matrix(y_test, model_to_confuse.predict(X_test))\n",
    "    dicto[dictionary_string]['confuse'] = confuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-cherry",
   "metadata": {},
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "harmful-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classy_dummy(dicto):\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    timing_buddy(dummy_clf, 'dummy', dicto)\n",
    "    confused_buddy(dummy_clf, 'dummy', dicto)\n",
    "    confused_buddy(dummy_clf, 'dummy', dicto)\n",
    "    dicto['dummy']['ROC_AUC_Score'] = roc_auc_score(y_test, dummy_clf.predict_proba(X_test)[:, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-extension",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "opposed-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVCmodeler(dicto):\n",
    "    SupportVectorClassifier = SVC()\n",
    "    timing_buddy(SupportVectorClassifier, 'SVC', dicto)\n",
    "    confused_buddy(SupportVectorClassifier, 'SVC', dicto)\n",
    "    dicto['SVC']['ROC_AUC_Score'] = roc_auc_score(y_test, SupportVectorClassifier.decision_function(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-tokyo",
   "metadata": {},
   "source": [
    "## Stochastic Gradiant Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "married-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGDModeler(dicto):\n",
    "    SGD_clf = SGDClassifier()\n",
    "    timing_buddy(SGD_clf, 'SGDClassfier', dicto)\n",
    "    confused_buddy(SGD_clf, 'SGDClassfier', dicto)\n",
    "    dicto['SGDClassfier']['ROC_AUC_Score'] = roc_auc_score(y_test, SGD_clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-birth",
   "metadata": {},
   "source": [
    "## SGD Hyper Paramter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGDHyperParameterer(loss_penalty_list):\n",
    "    SGD_clf = SGDClassifier(loss = loss_penalty_list[0], penalty=loss_penalty_list[1])\n",
    "    confuse = confusion_matrix(y_test, SGD_clf.predict(X_test))\n",
    "    tp = confuse[0][1]\n",
    "    fn = confuse[0][0]\n",
    "    recall = tp / (tp+fn)\n",
    "    return recall\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses= ['modified_huber', 'log']\n",
    "penalties = ['l2', 'l1', 'elasticnet']\n",
    "param_grid = {}\n",
    "count = 0\n",
    "for each_loss in losses:\n",
    "    for each_penalty in penalties:\n",
    "        param_grid[str(each_loss) + '_' + str(each_penalty)] = [each_loss, each_penalty]\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_Hyper_param_recall_score\n",
    "for items in param_grid:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-freeze",
   "metadata": {},
   "source": [
    "## BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distinct-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BagginsesModeler(dicto):\n",
    "    Classy_Baggins_DT = BaggingClassifier(n_estimators=10)\n",
    "    timing_buddy(Classy_Baggins_DT, 'BaggingClassifier', dicto)\n",
    "    confused_buddy(Classy_Baggins_DT, 'BaggingClassifier', dicto)\n",
    "    dicto['BaggingClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, Classy_Baggins_DT.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-adelaide",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "worst-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFModeler(dicto):\n",
    "    RandoForest = RandomForestClassifier(max_depth=110, min_samples_split = 1, min_samples_leaf=2, max_features='sqrt', n_estimators=1244)\n",
    "    \n",
    "    timing_buddy(RandoForest, 'RandomForestClassifier', dicto)\n",
    "    confused_buddy(RandoForest, 'RandomForestClassifier', dicto)\n",
    "    dicto['RandomForestClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, RandoForest.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-diameter",
   "metadata": {},
   "source": [
    "## random forest bayes hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "australian-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = ['dummy','SVC', 'SGDClassfier', 'BaggingClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'HistGradientBoostingClassifier']\n",
    "dicto = {}\n",
    "for each in model_set:\n",
    "    dicto[each] ={'confuse' : [], 'training_time' : 0, 'ROC_AUC_Score': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "israeli-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_RFModeler_auto(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    RandoForest = RandomForestClassifier(n_estimators=int(n_estimators), max_features='auto', max_depth=int(max_depth),\n",
    "                                         min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n",
    "    RandoForest.fit(X_train, np.ravel(y_train))\n",
    "    confuse = confusion_matrix(y_test, RandoForest.predict(X_test))\n",
    "    \n",
    "    tp = confuse[0][1]\n",
    "    fn = confuse[0][0]\n",
    "    recall = tp / (tp+fn)\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "substantial-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_RFModeler_sqrt(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    RandoForest = RandomForestClassifier(n_estimators=int(n_estimators), max_features='sqrt', max_depth=int(max_depth),\n",
    "                                         min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n",
    "    RandoForest.fit(X_train, np.ravel(y_train))\n",
    "    confuse = confusion_matrix(y_test, RandoForest.predict(X_test))\n",
    "    tp = confuse[0][0]\n",
    "    fp = confuse[1][0]\n",
    "    precision = tp/(tp + fp)\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dramatic-johns",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': (100, 2000), 'max_depth': (10, 110), 'min_samples_split': (2, 10), 'min_samples_leaf': (1, 5)}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "param_dicts = { 'n_estimators' : (100, 2000),\n",
    "              'max_depth' : (10,110),\n",
    "              'min_samples_split': (2,10),\n",
    "              'min_samples_leaf' : (1,5),\n",
    "              }\n",
    "#'max_features' : ('auto', 'sqrt'),\n",
    "\n",
    "\n",
    "print(param_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "agricultural-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_auto = BayesianOptimization(\n",
    "    bayes_RFModeler_auto,\n",
    "    pbounds=param_dicts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "conservative-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8292  \u001b[0m | \u001b[0m 99.58   \u001b[0m | \u001b[0m 4.138   \u001b[0m | \u001b[0m 2.99    \u001b[0m | \u001b[0m 1.808e+0\u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8299  \u001b[0m | \u001b[95m 86.24   \u001b[0m | \u001b[95m 2.283   \u001b[0m | \u001b[95m 5.452   \u001b[0m | \u001b[95m 999.6   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8297  \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 3.114   \u001b[0m | \u001b[0m 8.573   \u001b[0m | \u001b[0m 1.154e+0\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8284  \u001b[0m | \u001b[0m 29.15   \u001b[0m | \u001b[0m 4.801   \u001b[0m | \u001b[0m 8.869   \u001b[0m | \u001b[0m 1.491e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8292  \u001b[0m | \u001b[0m 53.33   \u001b[0m | \u001b[0m 4.411   \u001b[0m | \u001b[0m 3.588   \u001b[0m | \u001b[0m 213.2   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8293  \u001b[0m | \u001b[0m 63.1    \u001b[0m | \u001b[0m 3.077   \u001b[0m | \u001b[0m 5.858   \u001b[0m | \u001b[0m 1.467e+0\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8255  \u001b[0m | \u001b[0m 17.2    \u001b[0m | \u001b[0m 3.754   \u001b[0m | \u001b[0m 2.215   \u001b[0m | \u001b[0m 1.417e+0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 90.69   \u001b[0m | \u001b[0m 4.306   \u001b[0m | \u001b[0m 4.015   \u001b[0m | \u001b[0m 260.5   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8292  \u001b[0m | \u001b[0m 50.28   \u001b[0m | \u001b[0m 4.898   \u001b[0m | \u001b[0m 9.399   \u001b[0m | \u001b[0m 1.979e+0\u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8324  \u001b[0m | \u001b[95m 62.23   \u001b[0m | \u001b[95m 1.192   \u001b[0m | \u001b[95m 3.572   \u001b[0m | \u001b[95m 772.2   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8307  \u001b[0m | \u001b[0m 63.11   \u001b[0m | \u001b[0m 2.025   \u001b[0m | \u001b[0m 9.033   \u001b[0m | \u001b[0m 1.947e+0\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8321  \u001b[0m | \u001b[0m 98.35   \u001b[0m | \u001b[0m 1.638   \u001b[0m | \u001b[0m 2.608   \u001b[0m | \u001b[0m 1.378e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8294  \u001b[0m | \u001b[0m 51.11   \u001b[0m | \u001b[0m 3.03    \u001b[0m | \u001b[0m 2.753   \u001b[0m | \u001b[0m 528.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8294  \u001b[0m | \u001b[0m 34.94   \u001b[0m | \u001b[0m 3.939   \u001b[0m | \u001b[0m 6.909   \u001b[0m | \u001b[0m 169.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 94.15   \u001b[0m | \u001b[0m 2.134   \u001b[0m | \u001b[0m 8.65    \u001b[0m | \u001b[0m 1.1e+03 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.83    \u001b[0m | \u001b[0m 68.06   \u001b[0m | \u001b[0m 3.975   \u001b[0m | \u001b[0m 2.433   \u001b[0m | \u001b[0m 798.9   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8313  \u001b[0m | \u001b[0m 96.54   \u001b[0m | \u001b[0m 2.633   \u001b[0m | \u001b[0m 5.251   \u001b[0m | \u001b[0m 1.379e+0\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 60.56   \u001b[0m | \u001b[0m 2.71    \u001b[0m | \u001b[0m 2.246   \u001b[0m | \u001b[0m 779.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8301  \u001b[0m | \u001b[0m 57.55   \u001b[0m | \u001b[0m 3.271   \u001b[0m | \u001b[0m 6.776   \u001b[0m | \u001b[0m 765.8   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 70.2    \u001b[0m | \u001b[0m 1.824   \u001b[0m | \u001b[0m 5.773   \u001b[0m | \u001b[0m 770.7   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 106.0   \u001b[0m | \u001b[0m 2.95    \u001b[0m | \u001b[0m 3.018   \u001b[0m | \u001b[0m 1.378e+0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8287  \u001b[0m | \u001b[0m 68.32   \u001b[0m | \u001b[0m 4.54    \u001b[0m | \u001b[0m 2.04    \u001b[0m | \u001b[0m 776.1   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8305  \u001b[0m | \u001b[0m 59.78   \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 9.241   \u001b[0m | \u001b[0m 774.8   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8322  \u001b[0m | \u001b[0m 66.18   \u001b[0m | \u001b[0m 1.145   \u001b[0m | \u001b[0m 8.38    \u001b[0m | \u001b[0m 770.3   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8307  \u001b[0m | \u001b[0m 67.59   \u001b[0m | \u001b[0m 2.26    \u001b[0m | \u001b[0m 6.579   \u001b[0m | \u001b[0m 767.8   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "bayes_sampling_time_start= time.time()\n",
    "optimizer_auto.maximize(init_points=15, n_iter=10)\n",
    "bayes_sampling_time_stop= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "joint-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sqrt = BayesianOptimization(\n",
    "    bayes_RFModeler_sqrt,\n",
    "    pbounds=param_dicts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "supreme-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 93.51   \u001b[0m | \u001b[0m 4.937   \u001b[0m | \u001b[0m 5.694   \u001b[0m | \u001b[0m 568.4   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.83    \u001b[0m | \u001b[95m 25.34   \u001b[0m | \u001b[95m 1.639   \u001b[0m | \u001b[95m 8.309   \u001b[0m | \u001b[95m 451.9   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8292  \u001b[0m | \u001b[0m 70.55   \u001b[0m | \u001b[0m 4.098   \u001b[0m | \u001b[0m 4.483   \u001b[0m | \u001b[0m 665.9   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.83    \u001b[0m | \u001b[95m 58.23   \u001b[0m | \u001b[95m 3.88    \u001b[0m | \u001b[95m 5.545   \u001b[0m | \u001b[95m 1.828e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 15.52   \u001b[0m | \u001b[0m 4.54    \u001b[0m | \u001b[0m 5.521   \u001b[0m | \u001b[0m 715.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8275  \u001b[0m | \u001b[0m 22.09   \u001b[0m | \u001b[0m 3.268   \u001b[0m | \u001b[0m 9.804   \u001b[0m | \u001b[0m 1.975e+0\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 95.41   \u001b[0m | \u001b[0m 4.049   \u001b[0m | \u001b[0m 8.341   \u001b[0m | \u001b[0m 131.5   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8276  \u001b[0m | \u001b[0m 23.1    \u001b[0m | \u001b[0m 3.678   \u001b[0m | \u001b[0m 5.599   \u001b[0m | \u001b[0m 1.916e+0\u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.8308  \u001b[0m | \u001b[95m 71.11   \u001b[0m | \u001b[95m 2.997   \u001b[0m | \u001b[95m 9.542   \u001b[0m | \u001b[95m 1.836e+0\u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 16.68   \u001b[0m | \u001b[0m 3.807   \u001b[0m | \u001b[0m 4.496   \u001b[0m | \u001b[0m 1.08e+03\u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.8326  \u001b[0m | \u001b[95m 96.26   \u001b[0m | \u001b[95m 1.02    \u001b[0m | \u001b[95m 2.78    \u001b[0m | \u001b[95m 1.286e+0\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8128  \u001b[0m | \u001b[0m 12.17   \u001b[0m | \u001b[0m 4.139   \u001b[0m | \u001b[0m 5.006   \u001b[0m | \u001b[0m 1.292e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8098  \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 4.625   \u001b[0m | \u001b[0m 7.336   \u001b[0m | \u001b[0m 120.2   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8294  \u001b[0m | \u001b[0m 76.53   \u001b[0m | \u001b[0m 3.512   \u001b[0m | \u001b[0m 3.035   \u001b[0m | \u001b[0m 742.5   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8297  \u001b[0m | \u001b[0m 69.66   \u001b[0m | \u001b[0m 3.285   \u001b[0m | \u001b[0m 9.052   \u001b[0m | \u001b[0m 471.0   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.8326  \u001b[0m | \u001b[95m 110.0   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 1.244e+0\u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8139  \u001b[0m | \u001b[0m 12.26   \u001b[0m | \u001b[0m 2.437   \u001b[0m | \u001b[0m 6.892   \u001b[0m | \u001b[0m 528.2   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 66.06   \u001b[0m | \u001b[0m 3.223   \u001b[0m | \u001b[0m 7.939   \u001b[0m | \u001b[0m 409.9   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 109.8   \u001b[0m | \u001b[0m 1.658   \u001b[0m | \u001b[0m 4.597   \u001b[0m | \u001b[0m 1.246e+0\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8301  \u001b[0m | \u001b[0m 108.7   \u001b[0m | \u001b[0m 2.306   \u001b[0m | \u001b[0m 8.205   \u001b[0m | \u001b[0m 1.174e+0\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8309  \u001b[0m | \u001b[0m 109.1   \u001b[0m | \u001b[0m 2.741   \u001b[0m | \u001b[0m 6.85    \u001b[0m | \u001b[0m 1.351e+0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 109.7   \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 6.378   \u001b[0m | \u001b[0m 1.769e+0\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8305  \u001b[0m | \u001b[0m 109.0   \u001b[0m | \u001b[0m 2.466   \u001b[0m | \u001b[0m 9.963   \u001b[0m | \u001b[0m 821.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8301  \u001b[0m | \u001b[0m 109.9   \u001b[0m | \u001b[0m 3.986   \u001b[0m | \u001b[0m 2.436   \u001b[0m | \u001b[0m 909.7   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8281  \u001b[0m | \u001b[0m 31.65   \u001b[0m | \u001b[0m 4.738   \u001b[0m | \u001b[0m 9.692   \u001b[0m | \u001b[0m 873.1   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "bayes_sampling_time_start= time.time()\n",
    "optimizer_sqrt.maximize(init_points=15, n_iter=10)\n",
    "bayes_sampling_time_stop= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "desirable-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.69563031991323\n"
     ]
    }
   ],
   "source": [
    "print((bayes_sampling_time_stop - bayes_sampling_time_start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-bryan",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dental-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoostModeler(dicto):\n",
    "    adaira_the_classifier = AdaBoostClassifier(n_estimators=100)\n",
    "    timing_buddy(adaira_the_classifier, 'AdaBoostClassifier', dicto)\n",
    "    confused_buddy(adaira_the_classifier, 'AdaBoostClassifier', dicto)\n",
    "    dicto['AdaBoostClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, adaira_the_classifier.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-performer",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "iraqi-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradBoostModeler(dicto):\n",
    "    grady_the_boosted = GradientBoostingClassifier(n_estimators=100)\n",
    "    timing_buddy(grady_the_boosted, 'GradientBoostingClassifier', dicto)\n",
    "    confused_buddy(grady_the_boosted, 'GradientBoostingClassifier', dicto)\n",
    "    dicto['GradientBoostingClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, grady_the_boosted.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-ridge",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "marine-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason this model didn't like my functions. So long form it is!\n",
    "def HistGrad_modeler(dicto):\n",
    "    histamine_reaction = HistGradientBoostingClassifier()\n",
    "\n",
    "    hist_time_start = time.time()\n",
    "    histamine_reaction.fit(X_train, np.ravel(y_train))\n",
    "    hist_time_stop = time.time()\n",
    "    hist_train_time = hist_time_stop - hist_time_start\n",
    "    dicto['HistGradientBoostingClassifier']['training_time'] = hist_train_time\n",
    "    confuse = confusion_matrix(y_test, histamine_reaction.predict(X_test))\n",
    "    dicto['HistGradientBoostingClassifier']['confuse'] = confuse\n",
    "    dicto['HistGradientBoostingClassifier']['ROC_AUC_Score'] = roc_auc_score(y_test, histamine_reaction.predict_proba(X_test)[:, 1])    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-nashville",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-procurement",
   "metadata": {},
   "source": [
    "#precision = tp/(tp+fp)\n",
    "Maximize this for medical or security scenarios, don't wanna miss actual sicknesses\n",
    "\n",
    "#recall= tp/(tp+fn) \n",
    "maximize this for spam, don't wanna be hiding real emails\n",
    "\n",
    "specificity(tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "compact-given",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def medical_evaluator(dicto):\n",
    "    bestmodel = \"\"\n",
    "    training_time= 0\n",
    "    precision = 0\n",
    "    for key, value in dicto.items():\n",
    "        for underkey, under_value in value.items():\n",
    "            tp = dicto[key]['confuse'][0][0]\n",
    "            fp = dicto[key]['confuse'][1][0]\n",
    "            temp_precision = tp/(tp + fp)\n",
    "            if temp_precision > precision:\n",
    "                precision = temp_precision\n",
    "                bestmodel = key\n",
    "                training_time = dicto[key]['training_time']\n",
    "        return bestmodel, precision, training_time\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "expired-danger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spam_evaluator(dicto):\n",
    "    bestmodel = \"\"\n",
    "    training_time= 0\n",
    "    recall = 0\n",
    "    for key, value in dicto.items():\n",
    "        for underkey, under_value in value.items():\n",
    "            tp = dicto[key]['confuse'][0][0]\n",
    "            fn = dicto[key]['confuse'][0][1]\n",
    "            temp_recall = tp/(tp + fn)\n",
    "            if temp_recall > recall:\n",
    "                recall = temp_recall\n",
    "                bestmodel = key\n",
    "                training_time = dicto[key]['training_time']\n",
    "        return bestmodel, recall, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "inside-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chonky_model_aggregator(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #Models to explore\n",
    "    model_set = ['dummy','SVC', 'SGDClassfier', 'BaggingClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'GradientBoostingClassifier', 'HistGradientBoostingClassifier']\n",
    "    model_stats = {}\n",
    "    for each in model_set:\n",
    "        model_stats[each] ={'confuse' : [], 'training_time' : 0, 'ROC_AUC_Score': 0}\n",
    "    #model running\n",
    "    classy_dummy(model_stats)\n",
    "    SVCmodeler(model_stats)\n",
    "    SGDModeler(model_stats)\n",
    "    BagginsesModeler(model_stats)\n",
    "    RFModeler(model_stats)\n",
    "    AdaBoostModeler(model_stats)\n",
    "    GradBoostModeler(model_stats)\n",
    "    HistGrad_modeler(model_stats)\n",
    "\n",
    "\n",
    "    #best_med_model, med_precision, med_time = medical_evaluator(model_stats)\n",
    "    #best_spam_model, spam_recall, spam_time = spam_evaluator(model_stats)\n",
    "    #print(\"The best medical model (Optimizing for precision) is \" + best_med_model + \" It's precision score was\" + str(round(med_precision,3)) + \" and it took \" + str(round(med_time,2)) +\" seconds to run.\")\n",
    "    #print(\"\")\n",
    "    #print(\"The best spam model (Optimizing for recall) is \" + best_spam_model + \" It's recall score was\" +str(round(spam_recall, 3)) +\" and it took \" + str(round(spam_time, 2) +\" seconds to run.\")\n",
    "    return model_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-compact",
   "metadata": {},
   "source": [
    "#Wide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "level-clerk",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best medical model (Optimizing for precision) is dummy It's precision score was0.8037328238665589 and it took 0.017609596252441406 seconds to run.\n",
      "\n",
      "The best spam model (Optimizing for recall) is dummy It's recall score was1.0 and it took 0.017609596252441406 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "wide_data_model_stats = chonky_model_aggregator(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rising-latin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "SVC\n",
      "[[10680   258]\n",
      " [ 2200   471]]\n",
      "SGDClassfier\n",
      "[[10834   104]\n",
      " [ 2426   245]]\n",
      "BaggingClassifier\n",
      "[[10377   561]\n",
      " [ 2056   615]]\n",
      "RandomForestClassifier\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "AdaBoostClassifier\n",
      "[[10508   430]\n",
      " [ 1990   681]]\n",
      "GradientBoostingClassifier\n",
      "[[10616   322]\n",
      " [ 2090   581]]\n",
      "HistGradientBoostingClassifier\n",
      "[[10500   438]\n",
      " [ 2011   660]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in wide_data_model_stats.items():\n",
    "    print(key)\n",
    "    print(value['confuse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-israeli",
   "metadata": {},
   "source": [
    "#Narrow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "viral-extraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best medical model (Optimizing for precision) is dummy It's precision score was0.8037328238665589 and it took 0.023005008697509766 seconds to run.\n",
      "\n",
      "The best spam model (Optimizing for recall) is dummy It's recall score was1.0 and it took 0.023005008697509766 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "narrow_data_model_stats = chonky_model_aggregator(Narrow_X_train, Narrow_y_train, Narrow_X_test, Narrow_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "naked-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "SVC\n",
      "[[10680   258]\n",
      " [ 2200   471]]\n",
      "SGDClassfier\n",
      "[[10890    48]\n",
      " [ 2532   139]]\n",
      "BaggingClassifier\n",
      "[[10390   548]\n",
      " [ 2049   622]]\n",
      "RandomForestClassifier\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "AdaBoostClassifier\n",
      "[[10508   430]\n",
      " [ 1990   681]]\n",
      "GradientBoostingClassifier\n",
      "[[10616   322]\n",
      " [ 2090   581]]\n",
      "HistGradientBoostingClassifier\n",
      "[[10485   453]\n",
      " [ 1992   679]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in narrow_data_model_stats.items():\n",
    "    print(key)\n",
    "    print(value['confuse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "waiting-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#That didn't go well, so we're going to play with oversampling our smokers in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "directed-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_to_oversample= X_train.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "optional-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_mask = Xy_to_oversample.smokes == 'yes'\n",
    "Xy_oversampled = resample(Xy_to_oversample[Xy_mask], n_samples=20000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "shared-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_X_train = Xy_oversampled.drop('smokes', axis=1)    \n",
    "oversampled_y_train = Xy_oversampled.smokes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-draft",
   "metadata": {},
   "source": [
    "#resampled Wide Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "sunset-laugh",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best medical model (Optimizing for precision) is dummy It's precision score was0.8037328238665589 and it took 0.016995906829833984 seconds to run.\n",
      "\n",
      "The best spam model (Optimizing for recall) is dummy It's recall score was1.0 and it took 0.016995906829833984 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "wide_data_model_stats = chonky_model_aggregator(oversampled_X_train, oversampled_y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "finished-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "SVC\n",
      "[[10680   258]\n",
      " [ 2200   471]]\n",
      "SGDClassfier\n",
      "[[10834   104]\n",
      " [ 2426   245]]\n",
      "BaggingClassifier\n",
      "[[10377   561]\n",
      " [ 2056   615]]\n",
      "RandomForestClassifier\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "AdaBoostClassifier\n",
      "[[10508   430]\n",
      " [ 1990   681]]\n",
      "GradientBoostingClassifier\n",
      "[[10616   322]\n",
      " [ 2090   581]]\n",
      "HistGradientBoostingClassifier\n",
      "[[10500   438]\n",
      " [ 2011   660]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in wide_data_model_stats.items():\n",
    "    print(key)a\n",
    "    print(value['confuse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-stroke",
   "metadata": {},
   "source": [
    "#Resampled Narrow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "complimentary-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_Xy_to_oversample= Narrow_X_train.join(Narrow_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "transsexual-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_Xy_mask = Narrow_Xy_to_oversample.smokes == 'yes'\n",
    "Narrow_Xy_oversampled = resample(Narrow_Xy_to_oversample[Narrow_Xy_mask], n_samples=20000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hollywood-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_oversampled_X_train = Narrow_Xy_oversampled.drop('smokes', axis=1)    \n",
    "Narrow_oversampled_y_train = Narrow_Xy_oversampled.smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "departmental-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best medical model (Optimizing for precision) is dummy It's precision score was0.8037328238665589 and it took 0.017003536224365234 seconds to run.\n",
      "\n",
      "The best spam model (Optimizing for recall) is dummy It's recall score was1.0 and it took 0.017003536224365234 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "narrow_resampled_data_model_stats = chonky_model_aggregator(Narrow_oversampled_X_train, Narrow_oversampled_y_train, Narrow_X_test, Narrow_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prostate-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "SVC\n",
      "[[10680   258]\n",
      " [ 2200   471]]\n",
      "SGDClassfier\n",
      "[[10876    62]\n",
      " [ 2510   161]]\n",
      "BaggingClassifier\n",
      "[[10342   596]\n",
      " [ 2061   610]]\n",
      "RandomForestClassifier\n",
      "[[10938     0]\n",
      " [ 2671     0]]\n",
      "AdaBoostClassifier\n",
      "[[10508   430]\n",
      " [ 1990   681]]\n",
      "GradientBoostingClassifier\n",
      "[[10616   322]\n",
      " [ 2090   581]]\n",
      "HistGradientBoostingClassifier\n",
      "[[10530   408]\n",
      " [ 2014   657]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in narrow_resampled_data_model_stats.items():\n",
    "    print(key)\n",
    "    print(value['confuse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "official-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = {'samples': (500,50000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fatty-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precise_sampling_bayes_box(samples):\n",
    "    \n",
    "    Xy_to_oversample= X_train.join(y_train)\n",
    "    Xy_mask = Xy_to_oversample.smokes == 'yes'\n",
    "    Xy_oversampled = resample(Xy_to_oversample[Xy_mask], n_samples=int(samples), replace=True)\n",
    "    oversampled_X_train = Xy_oversampled.drop('smokes', axis=1)    \n",
    "    oversampled_y_train = Xy_oversampled.smokes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #testing the data\n",
    "    model_stats = chonky_model_aggregator(oversampled_X_train, oversampled_y_train, X_test, y_test)\n",
    "    best_med_model, med_precision, med_time = medical_evaluator(model_stats)\n",
    "    return med_precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "material-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    precise_sampling_bayes_box,\n",
    "    pbounds=pbounds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alive-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  samples  |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 4.372e+0\u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 4.173e+0\u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 9.848e+0\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.144e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 2.488e+0\u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 9.076e+0\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 5.892e+0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.039e+0\u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.206e+0\u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.786e+0\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 1.599e+0\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 2.023e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 4.037e+0\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 1.797e+0\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 1.017e+0\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 4.655e+0\u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 5e+04   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 503.9   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 5e+04   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 2.743e+0\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 502.1   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.547e+0\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 4.726e+0\u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 7.469e+0\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8037  \u001b[0m | \u001b[0m 3.426e+0\u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "bayes_sampling_time_start= time.time()\n",
    "optimizer.maximize(init_points=15, n_iter=10)\n",
    "bayes_sampling_time_stop= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "multiple-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.081936113701926\n"
     ]
    }
   ],
   "source": [
    "print(((bayes_sampling_time_stop- bayes_sampling_time_start)/60)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-korean",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
