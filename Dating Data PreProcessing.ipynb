{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "early-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "determined-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/wrangled_dating_data.csv')\n",
    "df_ethnicity = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/wrangled_ethnicity_data.csv')\n",
    "df_language = pd.read_csv('C:/Users/Prathmun/Documents/Springboard Jupyter/Capstone 2/DataDataCapstone/derived_data/wrangled_language_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ethical-pharmacy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54433, 15)\n",
      "age              int64\n",
      "status          object\n",
      "sex             object\n",
      "orientation     object\n",
      "body_type       object\n",
      "diet            object\n",
      "drinks          object\n",
      "drugs           object\n",
      "education       object\n",
      "height         float64\n",
      "job             object\n",
      "pets            object\n",
      "religion        object\n",
      "sign            object\n",
      "smokes          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Next three boxes we're just checking the integrity of our dataframe and reminding ourself of which columns need to be scaled\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "standard-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 10)\n",
      "asian                     int64\n",
      "white                     int64\n",
      "black                     int64\n",
      "other                     int64\n",
      "hispanic / latin          int64\n",
      "pacific islander          int64\n",
      "native american           int64\n",
      "middle eastern            int64\n",
      "indian                    int64\n",
      "ethnicity_multiplicity    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_ethnicity.shape)\n",
    "print(df_ethnicity.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "automated-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no                43895\n",
      "sometimes          3787\n",
      "when drinking      3040\n",
      "yes                2231\n",
      "trying to quit     1480\n",
      "Name: smokes, dtype: int64\n",
      "no     43895\n",
      "yes    10538\n",
      "Name: smokes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We're going to simplifiy our target variable. The notion is that we're sorting out people who smoke at all, and people who don't\n",
    "print(df.smokes.value_counts())\n",
    "df.smokes.replace(to_replace=['trying to quit', 'when drinking', 'sometimes' ], value='yes', inplace=True)\n",
    "print(df.smokes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "forced-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 80)\n",
      "bulgarian              int64\n",
      "swahili                int64\n",
      "dutch                  int64\n",
      "maori                  int64\n",
      "tibetan                int64\n",
      "                      ...   \n",
      "thai                   int64\n",
      "farsi                  int64\n",
      "fluency_score        float64\n",
      "multifluent_score      int64\n",
      "num_spoken             int64\n",
      "Length: 80, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_language.shape)\n",
    "print(df_language.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "banned-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_scaled = ['age', 'height', 'ethnicity_multiplicity', 'multifluent_score', 'num_spoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "subtle-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 105)\n",
      "    age     status sex orientation       body_type               diet  \\\n",
      "0  22.0     single   m    straight  a little extra  strictly anything   \n",
      "1  35.0     single   m    straight         average       mostly other   \n",
      "2  38.0  available   m    straight            thin           anything   \n",
      "3  23.0     single   m    straight            thin         vegetarian   \n",
      "4  29.0     single   m    straight        athletic           anything   \n",
      "\n",
      "     drinks        drugs                          education  height  ...  \\\n",
      "0  socially        never      working on college/university    75.0  ...   \n",
      "1     often    sometimes              working on space camp    70.0  ...   \n",
      "2  socially  unspecified     graduated from masters program    68.0  ...   \n",
      "3  socially  unspecified      working on college/university    71.0  ...   \n",
      "4  socially        never  graduated from college/university    66.0  ...   \n",
      "\n",
      "  indonesian yiddish esperanto romanian lithuanian  thai  farsi  \\\n",
      "0          0       0         0        0          0     0      0   \n",
      "1          0       0         0        0          0     0      0   \n",
      "2          0       0         0        0          0     0      0   \n",
      "3          0       0         0        0          0     0      0   \n",
      "4          0       0         0        0          0     0      0   \n",
      "\n",
      "   fluency_score  multifluent_score  num_spoken  \n",
      "0            1.0                  3           1  \n",
      "1            1.0                  5           3  \n",
      "2            3.0                  9           3  \n",
      "3            1.0                  4           2  \n",
      "4            1.0                  3           1  \n",
      "\n",
      "[5 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "df_pre_split = pd.concat([df, df_ethnicity, df_language], axis=1)\n",
    "print(df_pre_split.shape)\n",
    "print(df_pre_split.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "above-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I split out the language and ethnicity data frames before I dropped some of my NAN heavy rows. Going to just update this final dataframe by dropping those rows.\n",
    "df_pre_split= df_pre_split.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aa6cc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_pre_split.drop('smokes', axis=1)    \n",
    "y=df_pre_split.smokes      \n",
    "X_dummy_thicc = pd.get_dummies(X)\n",
    "y_dummy_thicc=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df1b23ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the split! The test_size is arbitrary for now, we'll adjust as our model(s) suggest.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummy_thicc, y, test_size=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "unlikely-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40824, 263)\n",
      "(13609, 263)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "573fc8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-bcb934a2f1c4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[columns_to_be_scaled] = Scaley_The_Standard_Scaler.fit_transform(X_train[columns_to_be_scaled])\n",
      "c:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-74-bcb934a2f1c4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[columns_to_be_scaled] = Scaley_The_Standard_Scaler.transform(X_test[columns_to_be_scaled])\n",
      "c:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "Scaley_The_Standard_Scaler= StandardScaler()\n",
    "X_train[columns_to_be_scaled] = Scaley_The_Standard_Scaler.fit_transform(X_train[columns_to_be_scaled])\n",
    "X_test[columns_to_be_scaled] = Scaley_The_Standard_Scaler.transform(X_test[columns_to_be_scaled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b905d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "    \n",
    "    \n",
    "# This utility was created because students were getting confused when they ran \n",
    "# their notebooks twice, the previous write-to-file code would do nothing and say  \n",
    "# nothing. The students thought the file was over-written when in fact, it was not -\n",
    "# generating hidden bugs in subsequent notebooks.\n",
    "\n",
    "def save_file(data, fname, dname):\n",
    "    \"\"\"Save a datafile (data) to a specific location (dname) and filename (fname)\n",
    "    \n",
    "    Currently valid formats are limited to CSV or PKL.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(dname):\n",
    "        os.mkdir(dname)\n",
    "        print(f'Directory {dname} was created.')\n",
    "        \n",
    "    fpath = os.path.join(dname, fname)\n",
    "    \n",
    "    \n",
    "    if os.path.exists(fpath):\n",
    "        print(\"A file already exists with this name.\\n\")\n",
    "\n",
    "        yesno = None\n",
    "        while yesno != \"Y\" and yesno != \"N\":\n",
    "            yesno = input('Do you want to overwrite? (Y/N)').strip()[0].capitalize()\n",
    "            if yesno == \"Y\":\n",
    "                print(f'Writing file.  \"{fpath}\"')\n",
    "                _save_file(data, fpath)\n",
    "                break  # Not required\n",
    "            elif yesno == \"N\":\n",
    "                print('\\nPlease re-run this cell with a new filename.')\n",
    "                break  # Not required\n",
    "            else:\n",
    "                print('\\nUnknown input, please enter \"Y\" or \"N\".')\n",
    "\n",
    "    else:  # path does not exist, ok to save the file\n",
    "        print(f'Writing file.  \"{fpath}\"')\n",
    "        _save_file(data, fpath)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def _save_file(data, fpath):\n",
    "    valid_ftypes = ['.csv', '.pkl']\n",
    "    \n",
    "    assert (fpath[-4:] in valid_ftypes), \"Invalid file type.  Use '.csv' or '.pkl'\"\n",
    "\n",
    "    # Figure out what kind of file we're dealing with by name\n",
    "    if fpath[-3:] == 'csv':\n",
    "        data.to_csv(fpath, index=False)\n",
    "    elif fpath[-3:] == 'pkl':\n",
    "        with open(fpath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d203267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\X_train_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\X_test_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\y_train_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\y_test_TS25_RS3.csv\"\n"
     ]
    }
   ],
   "source": [
    "save_file(pd.DataFrame(X_train), 'X_train_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(X_test), 'X_test_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(y_train), 'y_train_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(y_test), 'y_test_TS25_RS3.csv', 'derived_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-section",
   "metadata": {},
   "source": [
    "## Setting up a narrow set to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sound-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_columns_to_scale = ['age', 'height']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "impaired-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_X=df.drop('smokes', axis=1)    \n",
    "Narrow_y=df.smokes  \n",
    "Narrow_X = pd.get_dummies(Narrow_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "labeled-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the split! The test_size is arbitrary for now, we'll adjust as our model(s) suggest.\n",
    "Narrow_X_train, Narrow_X_test, Narrow_y_train, Narrow_y_test = train_test_split(Narrow_X, Narrow_y, test_size=0.25, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "public-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-14e1c26796cd>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Narrow_X_train[narrow_columns_to_scale] = Scaley_The_Standard_Scaler.fit_transform(Narrow_X_train[narrow_columns_to_scale])\n",
      "c:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "<ipython-input-54-14e1c26796cd>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Narrow_X_test[narrow_columns_to_scale] = Scaley_The_Standard_Scaler.transform(Narrow_X_test[narrow_columns_to_scale])\n",
      "c:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\indexing.py:1737: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "Scaley_The_Standard_Scaler= StandardScaler()\n",
    "Narrow_X_train[narrow_columns_to_scale] = Scaley_The_Standard_Scaler.fit_transform(Narrow_X_train[narrow_columns_to_scale])\n",
    "Narrow_X_test[narrow_columns_to_scale] = Scaley_The_Standard_Scaler.transform(Narrow_X_test[narrow_columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "naval-buying",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\Narrow_X_train_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\Narrow_X_test_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\Narrow_y_train_TS25_RS3.csv\"\n",
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)Y\n",
      "Writing file.  \"derived_data\\Narrow_y_test_TS25_RS3.csv\"\n"
     ]
    }
   ],
   "source": [
    "save_file(pd.DataFrame(Narrow_X_train), 'Narrow_X_train_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(Narrow_X_test), 'Narrow_X_test_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(Narrow_y_train), 'Narrow_y_train_TS25_RS3.csv', 'derived_data')\n",
    "save_file(pd.DataFrame(Narrow_y_test), 'Narrow_y_test_TS25_RS3.csv', 'derived_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-niagara",
   "metadata": {},
   "source": [
    " ## Setting up wide and narrow sets to oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "applicable-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30356    no\n",
       "Name: smokes, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "anticipated-thomas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'height', 'asian', 'white', 'black', 'other', 'hispanic / latin',\n",
       "       'pacific islander', 'native american', 'middle eastern',\n",
       "       ...\n",
       "       'religion_other', 'religion_other and laughing about it',\n",
       "       'religion_other and somewhat serious about it',\n",
       "       'religion_other and very serious about it',\n",
       "       'religion_other but not too serious about it', 'religion_unspecified',\n",
       "       'sign_Cares a lot', 'sign_does not care', 'sign_fun to think about',\n",
       "       'sign_just specified'],\n",
       "      dtype='object', length=263)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cellular-arrangement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 15)\n",
      "       age     status sex orientation       body_type               diet  \\\n",
      "20170   23     single   f    straight         average    mostly anything   \n",
      "49186   27     single   m    straight             fit    mostly anything   \n",
      "47573   28     single   m    straight            thin           anything   \n",
      "52659   23  available   f    bisexual          jacked  mostly vegetarian   \n",
      "30061   22     single   m    straight  a little extra    mostly anything   \n",
      "43262   27     single   m    straight  rather not say           anything   \n",
      "13161   28     single   m    straight         average  strictly anything   \n",
      "5336    35     single   f    straight         average           anything   \n",
      "51240   36     single   f    bisexual           curvy           anything   \n",
      "36143   37     single   m    straight         average    mostly anything   \n",
      "\n",
      "         drinks        drugs                          education  height  \\\n",
      "20170  socially        never              working on med school    62.0   \n",
      "49186  socially    sometimes     graduated from masters program    68.0   \n",
      "47573  socially    sometimes      working on college/university    66.0   \n",
      "52659  socially    sometimes  graduated from college/university    95.0   \n",
      "30061  socially        never                        unspecified    76.0   \n",
      "43262  socially  unspecified      working on college/university    70.0   \n",
      "13161  socially  unspecified     graduated from masters program    71.0   \n",
      "5336   socially  unspecified  graduated from college/university    65.0   \n",
      "51240  socially        never  graduated from college/university    58.0   \n",
      "36143     often    sometimes              working on space camp    70.0   \n",
      "\n",
      "                                     job                       pets  \\\n",
      "20170                              other                unspecified   \n",
      "49186        artistic / musical / writer  likes dogs and likes cats   \n",
      "47573               education / academia                unspecified   \n",
      "52659       science / tech / engineering  likes dogs and likes cats   \n",
      "30061                            student                unspecified   \n",
      "43262                            student    likes dogs and has cats   \n",
      "13161  banking / financial / real estate                unspecified   \n",
      "5336                   medicine / health    likes dogs and has cats   \n",
      "51240             executive / management                unspecified   \n",
      "36143               hospitality / travel  likes dogs and likes cats   \n",
      "\n",
      "                                         religion                sign smokes  \n",
      "20170  christianity and somewhat serious about it  fun to think about    yes  \n",
      "49186                 other and laughing about it  fun to think about    yes  \n",
      "47573                                 unspecified      just specified    yes  \n",
      "52659           agnosticism and laughing about it      just specified    yes  \n",
      "30061                                 unspecified      just specified    yes  \n",
      "43262                 other and laughing about it       does not care    yes  \n",
      "13161                                 catholicism      just specified    yes  \n",
      "5336                                  unspecified  fun to think about    yes  \n",
      "51240                                 unspecified      just specified    yes  \n",
      "36143   christianity but not too serious about it       does not care    yes  \n"
     ]
    }
   ],
   "source": [
    "df_mask = df.smokes == 'yes'\n",
    "oversampled_df = resample(df[df_mask], n_samples=20000, replace=True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-story",
   "metadata": {},
   "source": [
    "# THIS IS WHERE YOU LEFT OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "indonesian-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extra_smokers = pd.concat([df, oversampled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_columns_to_scale = ['age', 'height']\n",
    "oversampled_X=df_extra_smokers.drop('smokes', axis=1)    \n",
    "Narrow_y=df_extra_smokers.smokes  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversampled, y_oversampled = resample(Narrow_X[Narrow_y == 'no'],\n",
    "                                        Narrow_y[Narrow_y == 'no'],\n",
    "                                        replace=True,\n",
    "                                        n_samples=X_imbalanced[Narrow_y.shape[1])\n",
    "Narrow_X = np.vstack((Narrow_X))\n",
    "Narrow_y                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "Narrow_X = pd.get_dummies(Narrow_X)\n",
    "Narrow_X_train, Narrow_X_test, Narrow_y_train, Narrow_y_test = train_test_split(Narrow_X, Narrow_y, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaley_The_Standard_Scaler= StandardScaler()\n",
    "Narrow_X_train = Scaley_The_Standard_Scaler.fit_transform(Narrow_X_train[narrow_columns_to_scale])\n",
    "Narrow_X_test = Scaley_The_Standard_Scaler.transform(Narrow_X_test[narrow_columns_to_scale])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53a481214c1eee3a60e2d0cf4c920992715a8f8087f54faa7a39dc4a3c3b8bd0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
